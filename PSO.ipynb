{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "\n",
    "from sklearnex import patch_sklearn \n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from niapy.problems import Problem\n",
    "from niapy.task import Task\n",
    "from niapy.algorithms.basic import ParticleSwarmOptimization\n",
    "\n",
    "from Function import svm_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/merge_data/seq_rbp/transcript2pse_in_one*rbp_pvalue_cutoff10-3_-log10__train__x.npy\")\n",
    "feature_names = pd.read_csv(\"data/merge_data/ALL/transcript2pse_in_one*rbp_pvalue__cutoff10-3.csv\").columns.drop([\"loc\", \"Transcript_stable_ID\"])\n",
    "\n",
    "# X = np.load(\"data/merge_data/seq_rbp/pse_in_one2__rbp_10-3_-log10__train__x.npy\")\n",
    "# feature_names = pd.read_csv(\"data/merge_data/ALL/transcript2pse_in_one2rbp_pvalue_cutoff10-3_-log10.csv\").columns.drop([\"loc\", \"Transcript_stable_ID\"])\n",
    "\n",
    "y = np.load(\"data/merge_data/seq_rbp/pse_in_one2__rbp_10-3_-log10__train__y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test_pval = np.load(\"data/merge_data/seq_rbp/t2p*r_p_10-3_-log10__trian__x__utest_pval.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 21168)\n",
      "(2264, 4665)\n"
     ]
    }
   ],
   "source": [
    "X = X_temp[:, u_test_pval < 0.05]\n",
    "print(X_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 2704)\n"
     ]
    }
   ],
   "source": [
    "X = X_temp[:, u_test_pval < 0.01]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 2704)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "np.save(\"data/merge_data/seq_rbp/pse_in_one*rbp_pvalue_cutoff10-3_-log10__utest_pval001__train__x.npy\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "\n",
    "cv_x, cv_y = svm_function.CV_balanced(X, y, fold)\n",
    "\n",
    "auroc_array = []\n",
    "feature_importances_array = []\n",
    "for i in range(fold):\n",
    "    x_train, y_train, x_test, y_test = svm_function.cv_train_test(cv_x, cv_y, i)\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    feature_importances_array.append(clf.feature_importances_)\n",
    "    \n",
    "    y_test_score = clf.predict_proba(x_test)[:, 1]\n",
    "    roc_score = metrics.roc_auc_score(y_test, y_test_score)\n",
    "    auroc_array.append(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7230769230769231,\n",
       " 0.7073732718894009,\n",
       " 0.662606978275181,\n",
       " 0.6783760683760683,\n",
       " 0.6092001316655694,\n",
       " 0.7181533903884134,\n",
       " 0.72,\n",
       " 0.527238314680711,\n",
       " 0.689680710994075,\n",
       " 0.6385780118499013]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_x, cv_y = svm_function.CV_balanced(X[:, np.sum(np.array(feature_importances_array), axis=0) > 0], y, fold)\n",
    "\n",
    "temp_auroc_array = []\n",
    "temp_feature_importances_array = []\n",
    "for i in range(fold):\n",
    "    x_train, y_train, x_test, y_test = svm_function.cv_train_test(cv_x, cv_y, i)\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    temp_feature_importances_array.append(clf.feature_importances_)\n",
    "    \n",
    "    y_test_score = clf.predict_proba(x_test)[:, 1]\n",
    "    roc_score = metrics.roc_auc_score(y_test, y_test_score)\n",
    "    temp_auroc_array.append(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6610937554508983\n",
      "0.6381885996747748\n"
     ]
    }
   ],
   "source": [
    "print(sum(temp_auroc_array) / len(temp_auroc_array))\n",
    "print(sum(auroc_array) / len(auroc_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4507\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'temp_feature_importances_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39marray(feature_importances_array), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39marray(temp_feature_importances_array), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_feature_importances_array' is not defined"
     ]
    }
   ],
   "source": [
    "print(sum(np.sum(np.array(feature_importances_array), axis=0) > 0))\n",
    "print(sum(np.sum(np.array(temp_feature_importances_array), axis=0) > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7267\n",
      "7402\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.sum(np.array(feature_importances_array) != 0, axis=0) > 5))\n",
    "print(sum(np.sum(np.array(temp_feature_importances_array) != 0, axis=0) > 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13168\n",
      "2557\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.sum(np.array(feature_importances_array) > np.average(np.array(feature_importances_array)), axis=0) != 0))\n",
    "print(sum(np.sum(np.array(temp_feature_importances_array) > np.average(np.array(temp_feature_importances_array)), axis=0) > 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = 1 - np.array(clf.feature_importances_)\n",
    "# array = np.array([1,1,5, 0, 7, 0.5])\n",
    "order = array.argsort()\n",
    "ranks = order.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(x):\n",
    "    C_Nu = \"Nu\" if x[0] > 0.5 else \"C\"\n",
    "    kernel_list = ['linear',\n",
    "                    'poly', \n",
    "                    'rbf', \n",
    "                    'sigmoid']\n",
    "    kernel = kernel_list[int(x[1] * 3)]\n",
    "    kernel = \"%s_%s\" % (C_Nu, kernel)\n",
    "    C = (20 * x[2]) - 10\n",
    "    logGamma = (20 * x[3]) - 10\n",
    "    degree = int(x[4] * 10)\n",
    "    coef0 = (20 * x[5]) - 10\n",
    "    n = x[6] if x[6] != 0 else 1e-7\n",
    "    \n",
    "    params = {\n",
    "        'kernel':kernel, \n",
    "        'C':C, \n",
    "        'logGamma':logGamma, \n",
    "        'degree':degree, \n",
    "        'coef0':coef0, \n",
    "        'n':n, \n",
    "    }\n",
    "    return params\n",
    "\n",
    "class eSVMFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99, size=1, max_iter=1000, fold=5):\n",
    "        super().__init__(dimension=X_train.shape[1] + 7, lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "        self.size = size\n",
    "        self.max_iter = max_iter\n",
    "        self.fold = fold\n",
    "        \n",
    "    def _evaluate(self, x):\n",
    "        params = get_params(x[:7])\n",
    "        \n",
    "        x = x[7:]\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        print(params)\n",
    "        if num_selected == 0:\n",
    "            # auroc = \n",
    "            return 1\n",
    "        else:\n",
    "            # auroc = 1\n",
    "            # auroc = cv_mp_esvm(self.X_train[:, selected], self.y_train, fold=self.fold, size=self.size, max_iter=self.max_iter,\n",
    "            #             **params \n",
    "            #             )['avg AUROC']\n",
    "            auroc = svm_function.cv_esvm_perf(self.X_train[:, selected], self.y_train, fold=self.fold, size=self.size, max_iter=self.max_iter,\n",
    "                        **params \n",
    "                        )['avg AUROC']\n",
    "        print(\"auroc %.4f, avg %.4f, std %.4f, selected %d\" % (auroc, sum(x) / len(x), np.std(x), num_selected))\n",
    "        print(\"socre=%.4f\" % (self.alpha * (1 - auroc) + (1 - self.alpha) * (num_selected / self.X_train.shape[1])))\n",
    "        return self.alpha * (1 - auroc) + (1 - (self.alpha)) * (num_selected / self.X_train.shape[1])\n",
    "        # return self.alpha * (1 - auroc) + (1 - (self.alpha / 2)) * (num_selected / self.X_train.shape[1]) + (1 - (self.alpha / 2)) * (sum(x) / len(x))\n",
    "\n",
    "class SVMFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99, max_iter=1000, fold=5):\n",
    "        super().__init__(dimension=X_train.shape[1] + 7, lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.fold = fold\n",
    "        \n",
    "    def _evaluate(self, x):\n",
    "        params = get_params(x[:7])\n",
    "        \n",
    "        x = x[7:]\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        print(params)\n",
    "        if num_selected == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            try:\n",
    "                auroc = svm_function.cv_svm_perf(self.X_train[:, selected], self.y_train, fold=self.fold, max_iter=self.max_iter,\n",
    "                            **params \n",
    "                            )['avg AUROC']\n",
    "            except:\n",
    "                auroc = 0.5\n",
    "        print(\"auroc %.4f, avg %.4f, std %.4f, selected %d\" % (auroc, sum(x) / len(x), np.std(x), num_selected))\n",
    "        print(\"socre=%.4f\" % (self.alpha * (1 - auroc) + (1 - self.alpha) * (num_selected / self.X_train.shape[1])))\n",
    "        return self.alpha * (1 - auroc) + (1 - (self.alpha)) * (num_selected / self.X_train.shape[1])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_importances_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m max_iter \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m      4\u001b[0m fold \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m----> 6\u001b[0m problem \u001b[39m=\u001b[39m eSVMFeatureSelection(X[:, np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39marray(feature_importances_array), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m], y, size\u001b[39m=\u001b[39msize, max_iter\u001b[39m=\u001b[39mmax_iter, fold\u001b[39m=\u001b[39mfold, alpha\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m)\n\u001b[1;32m      8\u001b[0m task \u001b[39m=\u001b[39m Task(problem, max_iters\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m      9\u001b[0m algorithm \u001b[39m=\u001b[39m ParticleSwarmOptimization(population_size\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_importances_array' is not defined"
     ]
    }
   ],
   "source": [
    "total_time = time.time()\n",
    "size = 1\n",
    "max_iter = 1000\n",
    "fold = 5\n",
    "\n",
    "problem = eSVMFeatureSelection(X[:, np.sum(np.array(feature_importances_array), axis=0) > 0], y, size=size, max_iter=max_iter, fold=fold, alpha=0.8)\n",
    "\n",
    "task = Task(problem, max_iters=50)\n",
    "algorithm = ParticleSwarmOptimization(population_size=10000, seed=1234)\n",
    "best_features, best_fitness = algorithm.run(task)\n",
    "params = get_params(best_features[:7])\n",
    "params['size'] = size\n",
    "params['fold'] = fold\n",
    "params['max_iter'] = max_iter\n",
    "\n",
    "selected_features = best_features[7:] > 0.5\n",
    "\n",
    "# print(\"subset eSVM train:\")\n",
    "# subset_perf = svm_function.cv_esvm_perf(X[:, np.sum(np.array(feature_importances_array), axis=0) > 0][:, selected_features], y, **params)\n",
    "\n",
    "\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print('Number of selected features: %s / %s' % (selected_features.sum(), X[:, np.sum(np.array(feature_importances_array), axis=0) > 0].shape[1]))\n",
    "print(\"best_fitness: %s\" % best_fitness)\n",
    "# print(\"Subset roc_score: %s\" % subset_perf['avg AUROC'])\n",
    "\n",
    "# total_time = time.time() - total_time\n",
    "# json_dict = {\n",
    "#     # \"all_perf\": all_perf,\n",
    "#     \"total_time\": total_time,\n",
    "#     \"subset_perf\": subset_perf,\n",
    "#     \"params\": params,\n",
    "#     \"selected_features\": list(selected_features.astype(str)),\n",
    "# }\n",
    "# print(json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = time.time()\n",
    "size = 1\n",
    "max_iter = 1000\n",
    "fold = 5\n",
    "\n",
    "problem = eSVMFeatureSelection(X, y, size=size, max_iter=max_iter, fold=fold, alpha=0.5)\n",
    "\n",
    "task = Task(problem, max_iters=50)\n",
    "algorithm = ParticleSwarmOptimization(population_size=4000, seed=1234)\n",
    "best_features, best_fitness = algorithm.run(task)\n",
    "params = get_params(best_features[:7])\n",
    "params['size'] = size\n",
    "params['fold'] = fold\n",
    "params['max_iter'] = max_iter\n",
    "\n",
    "selected_features = best_features[7:] > 0.5\n",
    "\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print('Number of selected features: %s / %s' % (selected_features.sum(), X.shape[1]))\n",
    "print(\"best_fitness: %s\" % best_fitness)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = time.time()\n",
    "max_iter = 1000\n",
    "fold = 5\n",
    "\n",
    "problem = SVMFeatureSelection(X, y, max_iter=max_iter, fold=fold, alpha=0.5)\n",
    "\n",
    "task = Task(problem, max_iters=50)\n",
    "algorithm = ParticleSwarmOptimization(population_size=4000, seed=1234)\n",
    "best_features, best_fitness = algorithm.run(task)\n",
    "params = get_params(best_features[:7])\n",
    "params['fold'] = fold\n",
    "params['max_iter'] = max_iter\n",
    "\n",
    "selected_features = best_features[7:] > 0.5\n",
    "\n",
    "print(\"params:\")\n",
    "print(params)\n",
    "print('Number of selected features: %s / %s' % (selected_features.sum(), X.shape[1]))\n",
    "print(\"best_fitness: %s\" % best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "esvm_space = {'kernel': {\n",
    "                    'C_linear': {'C': [-10, 10]},\n",
    "                    'C_poly': {'logGamma': [-10, 10], 'C': [-10, 10], 'degree': [1, 10], 'coef0': [-10, 10]},\n",
    "                    'C_rbf': {'logGamma': [-10, 10], 'C': [-10, 10]},\n",
    "                    'C_sigmoid': {'logGamma': [-10, 10], 'C': [-10, 10], 'coef0': [-10, 10]},\n",
    "                    'Nu_linear': {'n': [0, 1]},\n",
    "                    'Nu_poly': {'logGamma': [-10, 10], 'n': [0, 1], 'degree': [1, 10], 'coef0': [-10, 10]},\n",
    "                    'Nu_rbf': {'logGamma': [-10, 10], 'n': [0, 1]},\n",
    "                    'Nu_sigmoid': {'logGamma': [-10, 10], 'n': [0, 1], 'coef0': [-10, 10]}\n",
    "                    }\n",
    "        }\n",
    "\n",
    "input_file = \"data/merge_data/seq_rbp/pse_in_one2__rbp_10-3_-log10__train__x.npy\"\n",
    "label_file = \"data/merge_data/seq_rbp/pse_in_one2__rbp_10-3_-log10__train__y.npy\"\n",
    "print(\"Input file: %s\" % (input_file))\n",
    "data_x = np.load(input_file)\n",
    "print(\"Label file: %s\" % (label_file))\n",
    "data_y = np.load(label_file)\n",
    "\n",
    "max_iter = 1\n",
    "size = 1\n",
    "fold = 5\n",
    "seed = 1212\n",
    "pmap = optunity.parallel.create_pmap(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esvm_tuned_auroc(x_train, y_train, x_test, y_test, kernel='C_linear', C=0, logGamma=0, degree=0, coef0=0, n=0.5, size=size, max_iter=max_iter, **params):\n",
    "    model = svm_function.esvm_train_model(x_train, y_train, kernel=kernel, C=C, logGamma=logGamma, degree=degree, coef0=coef0, n=n, size=size, max_iter=max_iter)\n",
    "    roc_score = model.test(x_test, y_test)\n",
    "    print(\"AUROC: %.2f\" % roc_score)\n",
    "    return roc_score\n",
    "\n",
    "cv_decorator = optunity.cross_validated(x=data_x, y=data_y, num_folds=fold)\n",
    "cv_esvm_tuned_auroc = cv_decorator(esvm_tuned_auroc)\n",
    "optimal_svm_pars, info, _ = optunity.maximize_structured(cv_esvm_tuned_auroc, esvm_space, num_evals=args.num_evals, pmap=pmap)\n",
    "print(\"optunity done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn import metrics\n",
    "from itertools import repeat\n",
    "\n",
    "class multi_ensemble_svm():\n",
    "    def __init__(self):\n",
    "        self.model_array = None\n",
    "        self.model_size = None\n",
    "        self.hp = {\n",
    "            \"kernel\": 'C_linear', \"C\":0, \"logGamma\":0, \"degree\":0, \"coef0\":0, \"n\":0.5, \"max_iter\":1e7\n",
    "        }\n",
    "    \n",
    "    def train(self, data, label, ensemble_data_size=1, kernel='C_linear', C=0, logGamma=0, degree=0, coef0=0, n=0.5, max_iter=1e7):\n",
    "        train_time = time.time()\n",
    "        self.hp[\"kernel\"] = kernel\n",
    "        self.hp[\"C\"] = C\n",
    "        self.hp[\"logGamma\"] = logGamma\n",
    "        self.hp[\"degree\"] = degree\n",
    "        self.hp[\"coef0\"] = coef0\n",
    "        self.hp[\"n\"] = n\n",
    "        self.hp[\"max_iter\"] = max_iter\n",
    "        \n",
    "        x, y = svm_function.ensemble_data(data, label, size=ensemble_data_size)\n",
    "        self.model_size = len(x)\n",
    "        \n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "        # with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        result = pool.starmap(self._svm_train, tqdm.tqdm(zip(x, y), total=self.model_size))\n",
    "        self.model_array = result\n",
    "        print(\"ensemble svm train: %.2fs\" % (time.time() - train_time))\n",
    "        pool.close()\n",
    "        return None\n",
    "\n",
    "    def _svm_train(self, d, l):\n",
    "        arr = np.arange(len(l))\n",
    "        np.random.shuffle(arr)\n",
    "        d = d[arr]\n",
    "        l = l[arr]\n",
    "        \n",
    "        m = svm_function.svm_train_model(d, l, self.hp[\"kernel\"], self.hp[\"C\"], self.hp[\"logGamma\"], self.hp[\"degree\"], self.hp[\"coef0\"], self.hp[\"n\"], max_iter=self.hp[\"max_iter\"])\n",
    "        return m\n",
    "    \n",
    "    def test(self, x, y):\n",
    "        pred_y, pred_y_score = self.predict(x)\n",
    "            \n",
    "        return metrics.roc_auc_score(y, pred_y_score)\n",
    "    \n",
    "    def _svm_predict(self, m, x):\n",
    "        return m.predict(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        output = None\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "        output = pool.starmap(self._svm_predict, tqdm.tqdm(zip(self.model_array, repeat(x)), total=self.model_size))\n",
    "        pred_y_score = np.sum(output, axis=0) / self.model_size\n",
    "        pred_y = np.where(pred_y_score >= 0.5, 1, 0)\n",
    "        \n",
    "        pool.close()\n",
    "        return pred_y, pred_y_score\n",
    "\n",
    "def cv_mp_esvm(data_x, data_y, fold=5,\n",
    "                kernel='C_rbf', \n",
    "                C=0, \n",
    "                logGamma=0, \n",
    "                degree=3, \n",
    "                coef0=0, \n",
    "                n=0, \n",
    "                size=10, \n",
    "                max_iter=1000):\n",
    "    cv_x, cv_y = svm_function.CV_balanced(data_x, data_y, fold)\n",
    "        \n",
    "    auroc_array = []\n",
    "    for i in range(fold):\n",
    "        x_train, y_train, x_test, y_test = svm_function.cv_train_test(cv_x, cv_y, i)\n",
    "        clf = multi_ensemble_svm()\n",
    "        clf.train(x_train, y_train, ensemble_data_size=size, kernel=kernel, \n",
    "                C=C, \n",
    "                logGamma=logGamma, \n",
    "                degree=degree, \n",
    "                coef0=coef0, \n",
    "                n=n, \n",
    "                max_iter=max_iter)\n",
    "        auroc_array.append(clf.test(x_test, y_test))\n",
    "    return sum(auroc_array) / len(auroc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/merge_data/seq_rbp/transcript2pse_in_one*rbp_pvalue_cutoff10-3_-log10__train__x.npy\")\n",
    "y = np.load(\"data/merge_data/seq_rbp/pse_in_one2__rbp_10-3_-log10__train__y.npy\")\n",
    "feature_names = pd.read_csv(\"data/merge_data/ALL/transcript2pse_in_one*rbp_pvalue__cutoff10-3.csv\").columns.drop([\"loc\", \"Transcript_stable_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/merge_data/seq_rbp/pse_in_one2__rbp_10-3_-log10__train__x.npy\")\n",
    "y = np.load(\"data/merge_data/seq_rbp/pse_in_one2__rbp_10-3_-log10__train__y.npy\")\n",
    "feature_names = pd.read_csv(\"data/merge_data/ALL/transcript2pse_in_one2rbp_pvalue_cutoff10-3_-log10.csv\").columns.drop([\"loc\", \"Transcript_stable_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_x, cv_y = svm_function.CV_balanced(X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cv_y[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "feature_names = dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1234)\n",
    "\n",
    "problem = SVMFeatureSelection(X_train, y_train)\n",
    "\n",
    "task = Task(problem, max_iters=100)\n",
    "algorithm = ParticleSwarmOptimization(population_size=10, seed=1234)\n",
    "best_features, best_fitness = algorithm.run(task)\n",
    "\n",
    "selected_features = best_features > 0.5\n",
    "print('Number of selected features:', selected_features.sum())\n",
    "print('Selected features:', ', '.join(feature_names[selected_features].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = multi_ensemble_svm()\n",
    "clf.train(X_train[:, selected_features], y_train, kernel='C_rbf', \n",
    "                                    C=-0.24806890111201105, \n",
    "                                    logGamma=-4.955918931113543, \n",
    "                                    degree=3, \n",
    "                                    coef0=0, \n",
    "                                    n=0, \n",
    "                                    ensemble_data_size=10, \n",
    "                                    max_iter=1000)\n",
    "subset_roc_score = clf.test(X_test[:, selected_features], y_test)\n",
    "\n",
    "\n",
    "clf = multi_ensemble_svm()\n",
    "clf.train(X_train, y_train, kernel='C_rbf', \n",
    "                                    C=-0.24806890111201105, \n",
    "                                    logGamma=-4.955918931113543, \n",
    "                                    degree=3, \n",
    "                                    coef0=0, \n",
    "                                    n=0, \n",
    "                                    ensemble_data_size=10, \n",
    "                                    max_iter=1000)\n",
    "roc_score = clf.test(X_test, y_test)\n",
    "print('Subset roc_score:', subset_roc_score)\n",
    "print('All roc_score:', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm_function.esvm_train_model(X_train[:, selected_features], y_train, kernel='C_rbf', \n",
    "                                    C=-0.24806890111201105, \n",
    "                                    logGamma=-4.955918931113543, \n",
    "                                    degree=3, \n",
    "                                    coef0=0, \n",
    "                                    n=0, \n",
    "                                    size=10, \n",
    "                                    max_iter=1000)\n",
    "roc_score = model.test(X_test[:, selected_features], y_test)\n",
    "print('Subset roc_score:', roc_score)\n",
    "\n",
    "model = svm_function.esvm_train_model(X_train, y_train, kernel='C_rbf', \n",
    "                                    C=-0.24806890111201105, \n",
    "                                    logGamma=-4.955918931113543, \n",
    "                                    degree=3, \n",
    "                                    coef0=0, \n",
    "                                    n=0, \n",
    "                                    size=10, \n",
    "                                    max_iter=1000)\n",
    "roc_score = model.test(X_test, y_test)\n",
    "print('All roc_score:', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "model_selected = SVC()\n",
    "model_all = SVC()\n",
    "\n",
    "model_selected.fit(X_train[:, selected_features], y_train)\n",
    "decision_values = model_selected.decision_function(X_test[:, selected_features])\n",
    "roc_score = metrics.roc_auc_score(y_test, decision_values)\n",
    "\n",
    "print('Subset roc_score:', roc_score)\n",
    "\n",
    "model_all.fit(X_train, y_train)\n",
    "decision_values = model_all.decision_function(X_test)\n",
    "roc_score = metrics.roc_auc_score(y_test, decision_values)\n",
    "print('All Features roc_score:', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features, best_fitness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jand_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
