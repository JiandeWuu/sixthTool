{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- k4:\n",
    "  - score: 0.804\n",
    "  - macro: 0.575\n",
    "- k123: \n",
    "  - score: 0.669\n",
    "  - macro: 0.487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2432, 256)\n",
      "(2432,)\n"
     ]
    }
   ],
   "source": [
    "data_x = np.load(\"data/k_mers/k4_datax.npy\")\n",
    "data_y = np.load(\"data/k_mers/k4_datay.npy\")\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.20, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 187, 2245]))\n",
      "(array([0, 1]), array([ 147, 1798]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(data_y, return_counts=True))\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.8049281314168378\n",
      "macro: 0.5755699279849549\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', C=1, class_weight='balanced').fit(x_train, y_train)\n",
    "            \n",
    "score = clf.score(x_test, y_test)\n",
    "print(\"score:\", score)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"macro:\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7484 5884 4306 ... 6343 5368 5271]\n",
      " [2970 2204 1449 ... 2501 3457 2516]\n",
      " [2302 2323 1042 ... 1991  876  941]\n",
      " ...\n",
      " [   3    2    1 ...    5   10    4]\n",
      " [   7    2    4 ...    4    2    3]\n",
      " [   4    3    9 ...    4    0    1]]\n",
      "(3998, 16)\n",
      "(3998, 16)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "row_count = np.array(row_count)\n",
    "print(row_count)\n",
    "z = stats.zscore(row_count, axis=1, ddof=1)\n",
    "print(row_count.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/linear_features/cdhit80_data_seq_loc75_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2432, 256)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def build_vocab(data):\n",
    "    word_counts = Counter(row.lower() for sample in data for row in sample)\n",
    "    vocab = [w for w, f in iter(word_counts.items())]\n",
    "    return vocab\n",
    "    \n",
    "def k_mers(data, n):\n",
    "    kmer_array = [[s[i:i + n].lower() for i in range(len(s) - n)] for s in data]\n",
    "    vocab = build_vocab(kmer_array)\n",
    "    return kmer_array, vocab\n",
    "\n",
    "data_y = np.where(df[\"loc\"].to_numpy() == \"Cytosolic\", 1, 0)\n",
    "\n",
    "data_x = None\n",
    "for k in range(4, 5):\n",
    "    kmer_array, vocab = k_mers(df[\"Sequence\"], k)\n",
    "    \n",
    "    k_array = None\n",
    "    for x in kmer_array:\n",
    "        has_v, counts = np.unique(x, return_counts=True)\n",
    "        \n",
    "        count_array = []\n",
    "        for v in vocab:\n",
    "            if v in has_v:\n",
    "                count_array.append(counts[list(has_v).index(v)] / sum(counts))\n",
    "            else:\n",
    "                count_array.append(0)\n",
    "        if k_array is None:\n",
    "            k_array = np.array([count_array])\n",
    "        else:\n",
    "            k_array = np.append(k_array, [count_array], axis=0)\n",
    "        # counter_array = []\n",
    "        # for v, n in zip(x_counter.keys(), x_counter.values()):\n",
    "            \n",
    "        #     print(v)\n",
    "        #     print(n)\n",
    "    # print(k_array)\n",
    "    if data_x is None:\n",
    "        data_x = k_array\n",
    "    else:\n",
    "        data_x = np.append(data_x, k_array, axis=1)\n",
    "    print(data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/k_mers/k4_datax\", data_x)\n",
    "np.save(\"data/k_mers/k4_datay\", data_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
