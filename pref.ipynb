{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "import statistics\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from os.path import isfile\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "\n",
    "from libsvm.svmutil import svm_problem\n",
    "from libsvm.svmutil import svm_parameter\n",
    "from libsvm.svmutil import svm_train\n",
    "from libsvm.svmutil import svm_predict\n",
    "from libsvm.svmutil import evaluations\n",
    "\n",
    "from Function import svm_function\n",
    "\n",
    "# Filter out ConvergenceWarning, RuntimeWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'noneclip_merge__RBPpred__RBPPWM_10-3_or', 'esvm_f10_e512_s10_p8_t1000.json']\n",
      "['All', 'eclip_merge__RBPpred__RBPPWM_10-3_or', 'esvm_f10_e512_s10_p8_t1000.json']\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"data/RBP_eclip/output/\"\n",
    "data_path = \"data/RBP_eclip/All/merge/\"\n",
    "\n",
    "perf_list = []\n",
    "\n",
    "perf_file_list = [\"All___noneclip_merge__RBPpred__RBPPWM_10-3_or___esvm_f10_e512_s10_p8_t1000.json\",\n",
    "                  \"All___eclip_merge__RBPpred__RBPPWM_10-3_or___esvm_f10_e512_s10_p8_t1000.json\"]\n",
    "x_file_list = [\"noneclip_merge__RBPpred__RBPPWM_10-3_or.npy\",\n",
    "               \"eclip_merge__RBPpred__RBPPWM_10-3_or.npy\"]\n",
    "y_file_list = [\"noneclip__y.npy\",\n",
    "               \"eclip__y.npy\"]\n",
    "\n",
    "# perf_file_list = [\"All___ensembl_non-RBPeclip__model_predict__trian_cutoff___esvm_f10_e512_s10_p8_t1000.json\",\n",
    "#                   \"All___ensembl_non-RBPeclip__model_predict_proba___esvm_f10_e512_s10_p8_t1000.json\",\n",
    "#                   \"All___ensembl_RBPeclip_model__has_loc_predict___esvm_f10_e512_s10_p8_t1000.json\",\n",
    "#                   \"All___ensembl_RBPeclip_model__has_loc_predict_proba___esvm_f10_e512_s10_p8_t1000.json\",\n",
    "#                   \"All___RBP_eclip_has_non__predict___esvm_f10_e512_s10_p8_t1000.json\",\n",
    "#                   \"All___RBP_eclip_has_non__predict_proba___esvm_f10_e512_s10_p8_t1000.json\"]\n",
    "# x_file_list = [\"ensembl_non-RBPeclip__model_predict__trian_cutoff.npy\",\n",
    "#                \"ensembl_non-RBPeclip__model_predict_proba.npy\",\n",
    "#                \"ensembl_RBPeclip_model__has_loc_predict_proba.npy\",\n",
    "#                \"ensembl_RBPeclip_model__has_loc_predict.npy\",\n",
    "#                \"RBP_eclip_has_non__predict.npy\",\n",
    "#                \"RBP_eclip_has_non__predict_proba.npy\"]\n",
    "# y_file_list = [\"ensembl_non-RBPeclip__loc.npy\",\n",
    "#                \"ensembl_non-RBPeclip__loc.npy\",\n",
    "#                \"ensembl_RBPeclip_model__has_loc__y.npy\",\n",
    "#                \"ensembl_RBPeclip_model__has_loc__y.npy\",\n",
    "#                \"RBP_eclip_has_non__y.npy\",\n",
    "#                \"RBP_eclip_has_non__y.npy\"]\n",
    "\n",
    "for i in range(len(y_file_list)):\n",
    "\n",
    "    file_list = perf_file_list[i].split(\"___\")\n",
    "    print(file_list)\n",
    "    f = open(dir_path + perf_file_list[i])\n",
    "    perf = json.load(f)\n",
    "    f.close()\n",
    "    x = np.load(data_path + x_file_list[i])\n",
    "    u, c = np.unique(np.load(data_path + y_file_list[i]), return_counts=True)\n",
    "    perf_list.append([file_list[1], x.shape[1], x.shape[0], c[np.where(u == 0)[0][0]], c[np.where(u == 1)[0][0]],\n",
    "                      file_list[2],\n",
    "                        perf['avg Accy'], perf['std Accy'],\n",
    "                        perf['avg Recall'], perf['std Recall'],\n",
    "                        perf['avg Prec'], perf['std Prec'],\n",
    "                        perf['avg Spec'], perf['std Spec'],\n",
    "                        perf['avg Npv'], perf['std Npv'],\n",
    "                        perf['avg F1sc'], perf['std F1sc'],\n",
    "                        perf['avg AUROC'], perf['std AUROC']\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_selection', 'noneclip_merge', 'e512u25f10s10t1000.json']\n"
     ]
    }
   ],
   "source": [
    "perf_file_path = \"data/RBP_eclip/output/feature_selection__noneclip_merge__e512u25f10s10t1000.json\"\n",
    "perf_file = \"feature_selection__noneclip_merge__e512u25f10s10t1000.json\"\n",
    "x_file = \"data/RBP_eclip/All/merge/noneclip_merge__RBPpred__RBPPWM_10-3_or.npy\"\n",
    "y_file = \"data/RBP_eclip/All/merge/noneclip__y.npy\"\n",
    "\n",
    "file_list = perf_file.split(\"__\")\n",
    "print(file_list)\n",
    "f = open(perf_file_path)\n",
    "perf = json.load(f)\n",
    "f.close()\n",
    "x = np.load(x_file)\n",
    "u, c = np.unique(np.load(y_file), return_counts=True)\n",
    "\n",
    "selected_features_num = sum(np.array(perf['selected_features']) == 'True')\n",
    "perf = perf['subset_perf']\n",
    "perf_list.append(['feature_selection ' + file_list[1], selected_features_num, x.shape[0], c[np.where(u == 0)[0][0]], c[np.where(u == 1)[0][0]],\n",
    "                    file_list[2],\n",
    "                    perf['avg Accy'], perf['std Accy'],\n",
    "                    perf['avg Recall'], perf['std Recall'],\n",
    "                    perf['avg Prec'], perf['std Prec'],\n",
    "                    perf['avg Spec'], perf['std Spec'],\n",
    "                    perf['avg Npv'], perf['std Npv'],\n",
    "                    perf['avg F1sc'], perf['std F1sc'],\n",
    "                    perf['avg AUROC'], perf['std AUROC']\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(perf_list, columns=[\"name\", \"Feature num\", \"nums\", \"count_0\", \"count_1\", \"hp\",\n",
    "                                 \"avg Accy\", \"std Accy\",\n",
    "                                 \"avg Recall\", \"std Recall\",\n",
    "                                 \"avg Prec\", \"std Prec\",\n",
    "                                 \"avg Spec\", \"std Spec\",\n",
    "                                 \"avg Npv\", \"std Npv\",\n",
    "                                 \"avg F1sc\", \"std F1sc\",\n",
    "                                 \"avg AUROC\", \"std AUROC\"\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(perf_file_path)\n",
    "perf = json.load(f)\n",
    "f.close()\n",
    "x = np.load(x_file)\n",
    "\n",
    "# selected_features_num = sum(np.array(perf['selected_features']) == 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 22)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(perf['selected_features'])[:154] == 'True'), sum(np.array(perf['selected_features'])[154:] == 'True') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Feature num</th>\n",
       "      <th>nums</th>\n",
       "      <th>count_0</th>\n",
       "      <th>count_1</th>\n",
       "      <th>hp</th>\n",
       "      <th>avg Accy</th>\n",
       "      <th>std Accy</th>\n",
       "      <th>avg Recall</th>\n",
       "      <th>std Recall</th>\n",
       "      <th>avg Prec</th>\n",
       "      <th>std Prec</th>\n",
       "      <th>avg Spec</th>\n",
       "      <th>std Spec</th>\n",
       "      <th>avg Npv</th>\n",
       "      <th>std Npv</th>\n",
       "      <th>avg F1sc</th>\n",
       "      <th>std F1sc</th>\n",
       "      <th>avg AUROC</th>\n",
       "      <th>std AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noneclip_merge__RBPpred__RBPPWM_10-3_or</td>\n",
       "      <td>205</td>\n",
       "      <td>594</td>\n",
       "      <td>95</td>\n",
       "      <td>499</td>\n",
       "      <td>esvm_f10_e512_s10_p8_t1000.json</td>\n",
       "      <td>0.464166</td>\n",
       "      <td>0.113508</td>\n",
       "      <td>0.426327</td>\n",
       "      <td>0.147754</td>\n",
       "      <td>0.864958</td>\n",
       "      <td>0.061209</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.174374</td>\n",
       "      <td>0.182693</td>\n",
       "      <td>0.047926</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.146780</td>\n",
       "      <td>0.558009</td>\n",
       "      <td>0.100398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eclip_merge__RBPpred__RBPPWM_10-3_or</td>\n",
       "      <td>205</td>\n",
       "      <td>2237</td>\n",
       "      <td>269</td>\n",
       "      <td>1968</td>\n",
       "      <td>esvm_f10_e512_s10_p8_t1000.json</td>\n",
       "      <td>0.758183</td>\n",
       "      <td>0.023253</td>\n",
       "      <td>0.755099</td>\n",
       "      <td>0.023834</td>\n",
       "      <td>0.962120</td>\n",
       "      <td>0.017002</td>\n",
       "      <td>0.780627</td>\n",
       "      <td>0.101426</td>\n",
       "      <td>0.303581</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.845853</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>0.851919</td>\n",
       "      <td>0.048062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_selection noneclip_merge</td>\n",
       "      <td>98</td>\n",
       "      <td>594</td>\n",
       "      <td>95</td>\n",
       "      <td>499</td>\n",
       "      <td>e512u25f10s10t1000.json</td>\n",
       "      <td>0.626361</td>\n",
       "      <td>0.037818</td>\n",
       "      <td>0.629102</td>\n",
       "      <td>0.048918</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.028659</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.113942</td>\n",
       "      <td>0.238711</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.737755</td>\n",
       "      <td>0.034676</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>0.076546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  Feature num  nums  count_0  \\\n",
       "0  noneclip_merge__RBPpred__RBPPWM_10-3_or          205   594       95   \n",
       "1     eclip_merge__RBPpred__RBPPWM_10-3_or          205  2237      269   \n",
       "2         feature_selection noneclip_merge           98   594       95   \n",
       "\n",
       "   count_1                               hp  avg Accy  std Accy  avg Recall  \\\n",
       "0      499  esvm_f10_e512_s10_p8_t1000.json  0.464166  0.113508    0.426327   \n",
       "1     1968  esvm_f10_e512_s10_p8_t1000.json  0.758183  0.023253    0.755099   \n",
       "2      499          e512u25f10s10t1000.json  0.626361  0.037818    0.629102   \n",
       "\n",
       "   std Recall  avg Prec  std Prec  avg Spec  std Spec   avg Npv   std Npv  \\\n",
       "0    0.147754  0.864958  0.061209  0.656667  0.174374  0.182693  0.047926   \n",
       "1    0.023834  0.962120  0.017002  0.780627  0.101426  0.303581  0.031641   \n",
       "2    0.048918  0.895799  0.028659  0.613333  0.113942  0.238711  0.028384   \n",
       "\n",
       "   avg F1sc  std F1sc  avg AUROC  std AUROC  \n",
       "0  0.556386  0.146780   0.558009   0.100398  \n",
       "1  0.845853  0.016396   0.851919   0.048062  \n",
       "2  0.737755  0.034676   0.669131   0.076546  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/RBP_eclip/output/All_perf_0704.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"data/Pse_in_One2/my_DB/output/\"\n",
    "onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "perf_list = []\n",
    "for file_name in onlyfiles:\n",
    "    if (\"json\" in file_name) and not \".dvc\" in file_name and \"All\" in file_name:\n",
    "        file_list = file_name.split(\"__\")\n",
    "        print(file_list)\n",
    "        f = open(dir_path + file_name)\n",
    "        perf = json.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        u, c = np.unique(np.load(\"data/Pse_in_One2/my_DB/train/%s__%s__train_y.npy\" % (file_list[0], file_list[1])), return_counts=True)\n",
    "        perf_list.append([file_list[1], c[np.where(u == 0)[0][0]], c[np.where(u == 1)[0][0]], file_list[3][:-5],\n",
    "                          perf['avg Accy'], perf['std Accy'],\n",
    "                          perf['avg Recall'], perf['std Recall'],\n",
    "                          perf['avg Prec'], perf['std Prec'],\n",
    "                          perf['avg Spec'], perf['std Spec'],\n",
    "                          perf['avg Npv'], perf['std Npv'],\n",
    "                          perf['avg F1sc'], perf['std F1sc'],\n",
    "                          perf['avg AUROC'], perf['std AUROC']\n",
    "                          ])\n",
    "        \n",
    "df = pd.DataFrame(perf_list, columns=[\"name\", \"count_0\", \"count_1\", \"hp\", \n",
    "                                 \"avg Accy\", \"std Accy\",\n",
    "                                 \"avg Recall\", \"std Recall\",\n",
    "                                 \"avg Prec\", \"std Prec\",\n",
    "                                 \"avg Spec\", \"std Spec\",\n",
    "                                 \"avg Npv\", \"std Npv\",\n",
    "                                 \"avg F1sc\", \"std F1sc\",\n",
    "                                 \"avg AUROC\", \"std AUROC\"\n",
    "                                 ])#.sort_values(\"name\").to_csv(\"data/Pse_in_One2/my_DB/output/v230509__pref.csv\", index=False)\n",
    "\n",
    "# rbp_df = pd.DataFrame([])\n",
    "# rbp_df[\"name\"] = rbp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"data/Pse_in_One2/my_DB/train/\"\n",
    "onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "rbp_list = []\n",
    "for file_name in onlyfiles:\n",
    "    if (\"__train_y.npy\" in file_name) and not \".dvc\" in file_name:\n",
    "        file_list = file_name.split(\"__\")\n",
    "        rbp_list.append(file_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ensembl_has_rbpelic', 'NSUN2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'HLTF', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'ZC3H11A', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SF3B4', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'NIPBL', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'AKAP8L', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SAFB2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PABPC4', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DROSHA', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SERBP1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PPIG', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'ABCF1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'MATR3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FXR1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'GEMIN5', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'RBM27', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'XPO5', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'EWSR1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'AATF', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'GRSF1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'UCHL5', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX55', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'EXOSC5', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'NPM1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PUS1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'TNRC6A', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FKBP4', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FMR1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PUM2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'BUD13', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DHX30', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'GNL3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DKC1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PABPN1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'RPS11', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PCBP2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'G3BP1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'CPEB4', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FTO', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PUM1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'HNRNPU', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX24', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'CPSF6', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'KHSRP', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PHF6', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'EIF4G2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'TIAL1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'GTF2F1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'HNRNPA1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'LARP7', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'METAP2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SBDS', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SFPQ', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SRSF7', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SRSF1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'ZC3H8', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'WRN', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'NIP7', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'NKRF', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'NOL12', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PCBP1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PPIL4', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'LARP4', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PTBP1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'RBM5', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'UPF1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SUGP2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SUPV3L1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'AARS', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'APOBEC3C', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'AUH', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'CDC40', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX21', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX42', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX51', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX59', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'EFTUD2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'EIF3G', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FUBP3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FXR2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'HNRNPUL1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'IGF2BP1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'IGF2BP3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'KHDRBS1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX52', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'LIN28B', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'AKAP1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'UTP3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SF3A3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'WDR3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'EIF3H', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'HNRNPK', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'POLR2G', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'TROVE2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'AGGF1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'CSTF2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'HNRNPM', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'RPS5', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SF3B1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SLBP', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SUB1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'TARDBP', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'ZRANB2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SMNDC1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SAFB', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SDAD1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'WDR43', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'BCCIP', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'GPKOW', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'NONO', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'RPS3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PRPF4', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'PRPF8', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SND1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'UTP18', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'BCLAF1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX6', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FAM120A', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'IGF2BP2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'ZNF800', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'TIA1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'NCBP2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'NOLC1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'YBX3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'RBM22', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SLTM', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'STAU2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'U2AF2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'XRN2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'TBRG4', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'RBM15', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FASTKD2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'ILF3', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'LSM11', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SSB', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'HNRNPL', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'QKI', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'TRA2A', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'U2AF1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'MTPAP', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'RBFOX2', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'YWHAG', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'CSTF2T', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DGCR8', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'GRWD1', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'EIF3D', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'XRCC6', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'DDX3X', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'SRSF9', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'TAF15', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'HNRNPC', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'AQR', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'ZNF622', 'train_y', 'svm_p4_e512_f10.json']\n",
      "['ensembl_has_rbpelic', 'FUS', 'train_y', 'svm_p4_e512_f10.json']\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"data/Pse_in_One2/my_DB/output/\"\n",
    "onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "perf_list = []\n",
    "for file_name in onlyfiles:\n",
    "    if (\"json\" in file_name) and not \".dvc\" in file_name and \"All\" in file_name:\n",
    "        file_list = file_name.split(\"__\")\n",
    "        print(file_list)\n",
    "        f = open(dir_path + file_name)\n",
    "        perf = json.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        u, c = np.unique(np.load(\"data/Pse_in_One2/my_DB/train/%s__%s__train_y.npy\" % (file_list[0], file_list[1])), return_counts=True)\n",
    "        perf_list.append([file_list[1], c[np.where(u == 0)[0][0]], c[np.where(u == 1)[0][0]], file_list[3][:-5],\n",
    "                          perf['avg Accy'], perf['std Accy'],\n",
    "                          perf['avg Recall'], perf['std Recall'],\n",
    "                          perf['avg Prec'], perf['std Prec'],\n",
    "                          perf['avg Spec'], perf['std Spec'],\n",
    "                          perf['avg Npv'], perf['std Npv'],\n",
    "                          perf['avg F1sc'], perf['std F1sc'],\n",
    "                          perf['avg AUROC'], perf['std AUROC']\n",
    "                          ])\n",
    "        \n",
    "df = pd.DataFrame(perf_list, columns=[\"name\", \"count_0\", \"count_1\", \"hp\", \n",
    "                                 \"avg Accy\", \"std Accy\",\n",
    "                                 \"avg Recall\", \"std Recall\",\n",
    "                                 \"avg Prec\", \"std Prec\",\n",
    "                                 \"avg Spec\", \"std Spec\",\n",
    "                                 \"avg Npv\", \"std Npv\",\n",
    "                                 \"avg F1sc\", \"std F1sc\",\n",
    "                                 \"avg AUROC\", \"std AUROC\"\n",
    "                                 ])#.sort_values(\"name\").to_csv(\"data/Pse_in_One2/my_DB/output/v230509__pref.csv\", index=False)\n",
    "\n",
    "# rbp_df = pd.DataFrame([])\n",
    "# rbp_df[\"name\"] = rbp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(rbp_df, df, how=\"left\", on=\"name\").sort_values(\"name\").to_csv(\"data/Pse_in_One2/my_DB/output/v230613__cutoff_pref.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8311/943740313.py:1: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n",
      "  storage = optuna.storages.JournalStorage(\n"
     ]
    }
   ],
   "source": [
    "storage = optuna.storages.JournalStorage(\n",
    "        optuna.storages.JournalFileStorage(\"data/RBP_eclip/output/ensembl__optuna.log\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_col = []\n",
    "for i in range(205):\n",
    "    f_col.append(\"feature_%s\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_list = [\n",
    "    \"ensembl__merge_RBP_PWM__fs\",\n",
    "    \"ensembl__merge_RBP_PWM__random_sampler__fs\",\n",
    "    \"ensembl__merge_RBP_PWM10-4__random_sampler__fs\"\n",
    "]\n",
    "# x_list = [\n",
    "#     \"data/RBP_eclip/All/merge/ensembl__merge__RBPpred__RBPPWM_10-3_or.npy\",\n",
    "#     \"data/RBP_eclip/All/merge/ensembl__merge__RBPpred__RBPPWM_10-4_or.npy\"\n",
    "# ]\n",
    "y_list = [\n",
    "    \"data/RBP_eclip/All/merge/ensembl__y.npy\",\n",
    "    \"data/RBP_eclip/All/merge/ensembl__y.npy\",\n",
    "    \"data/RBP_eclip/All/merge/ensembl__y.npy\"\n",
    "]\n",
    "output_list = [\n",
    "    \"data/RBP_eclip/output/ensembl__merge_RBP_PWM__fs.json\",\n",
    "    \"data/RBP_eclip/output/ensembl__merge_RBP_PWM__random_sampler__fs.json\",\n",
    "    \"data/RBP_eclip/output/ensembl__merge_RBP_PWM10-4__random_sampler__fs.json\"\n",
    "]\n",
    "\n",
    "perf_list = []\n",
    "for i in range(len(study_list)):\n",
    "    study = optuna.load_study(study_name=study_list[i], storage=storage)\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    select_feature = [best_params[f] for f in f_col]\n",
    "    \n",
    "    f = open(output_list[i])\n",
    "    perf = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    u, c = np.unique(np.load(y_list[i]), return_counts=True)\n",
    "    perf_list.append([study_list[i], sum(select_feature), c[np.where(u == 0)[0][0]], c[np.where(u == 1)[0][0]],\n",
    "                        perf['avg Accy'], perf['std Accy'],\n",
    "                        perf['avg Recall'], perf['std Recall'],\n",
    "                        perf['avg Prec'], perf['std Prec'],\n",
    "                        perf['avg Spec'], perf['std Spec'],\n",
    "                        perf['avg Npv'], perf['std Npv'],\n",
    "                        perf['avg F1sc'], perf['std F1sc'],\n",
    "                        perf['avg AUROC'], perf['std AUROC']\n",
    "                        ])\n",
    "    \n",
    "df = pd.DataFrame(perf_list, columns=[\"name\", \"feature\", \"count_0\", \"count_1\", \n",
    "                                 \"avg Accy\", \"std Accy\",\n",
    "                                 \"avg Recall\", \"std Recall\",\n",
    "                                 \"avg Prec\", \"std Prec\",\n",
    "                                 \"avg Spec\", \"std Spec\",\n",
    "                                 \"avg Npv\", \"std Npv\",\n",
    "                                 \"avg F1sc\", \"std F1sc\",\n",
    "                                 \"avg AUROC\", \"std AUROC\"\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/RBP_eclip/output/feature_selection___ensembl__merge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8311/2765332447.py:1: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n",
      "  storage = optuna.storages.JournalStorage(\n"
     ]
    }
   ],
   "source": [
    "storage = optuna.storages.JournalStorage(\n",
    "        optuna.storages.JournalFileStorage(\"data/RBP_eclip/output/ensembl__optuna.log\"),\n",
    "    )\n",
    "# [(storage.get_study_name_from_id(temp_study._study_id), temp_study._study_id) for temp_study in storage.get_all_studies()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ensembl__merge_RBP_PWM__fs', 0),\n",
       " ('ensembl__merge_RBP_PWM', 1),\n",
       " ('ensembl__merge_RBP_PWM__t100000', 2),\n",
       " ('ensembl__merge_RBP_PWM__size', 3),\n",
       " ('ensembl__merge_RBP_PWM__random_sampler__fs', 5),\n",
       " ('ensembl__merge_RBP_PWM10-4__random_sampler__fs', 9),\n",
       " ('ensembl__merge_RBP_PWM10-3__random_sampler__fs', 10)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(storage.get_study_name_from_id(temp_study._study_id), temp_study._study_id) for temp_study in storage.get_all_studies()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.load_study(study_name=\"ensembl__merge_RBP_PWM__fs\", storage=storage)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=532, state=TrialState.COMPLETE, values=[0.8040063497139878], datetime_start=datetime.datetime(2023, 7, 5, 16, 18, 39, 661942), datetime_complete=datetime.datetime(2023, 7, 5, 16, 34, 3, 959489), params={'feature_0': False, 'feature_1': True, 'feature_2': True, 'feature_3': False, 'feature_4': False, 'feature_5': True, 'feature_6': True, 'feature_7': False, 'feature_8': True, 'feature_9': False, 'feature_10': False, 'feature_11': False, 'feature_12': False, 'feature_13': False, 'feature_14': False, 'feature_15': False, 'feature_16': True, 'feature_17': True, 'feature_18': True, 'feature_19': False, 'feature_20': True, 'feature_21': True, 'feature_22': True, 'feature_23': False, 'feature_24': False, 'feature_25': False, 'feature_26': False, 'feature_27': True, 'feature_28': True, 'feature_29': True, 'feature_30': True, 'feature_31': True, 'feature_32': False, 'feature_33': False, 'feature_34': False, 'feature_35': False, 'feature_36': False, 'feature_37': True, 'feature_38': True, 'feature_39': True, 'feature_40': True, 'feature_41': False, 'feature_42': True, 'feature_43': False, 'feature_44': False, 'feature_45': True, 'feature_46': False, 'feature_47': False, 'feature_48': True, 'feature_49': True, 'feature_50': True, 'feature_51': False, 'feature_52': True, 'feature_53': True, 'feature_54': True, 'feature_55': True, 'feature_56': False, 'feature_57': True, 'feature_58': False, 'feature_59': False, 'feature_60': False, 'feature_61': False, 'feature_62': True, 'feature_63': False, 'feature_64': True, 'feature_65': False, 'feature_66': True, 'feature_67': True, 'feature_68': True, 'feature_69': True, 'feature_70': True, 'feature_71': False, 'feature_72': True, 'feature_73': True, 'feature_74': True, 'feature_75': True, 'feature_76': True, 'feature_77': True, 'feature_78': True, 'feature_79': True, 'feature_80': True, 'feature_81': True, 'feature_82': False, 'feature_83': False, 'feature_84': True, 'feature_85': False, 'feature_86': False, 'feature_87': False, 'feature_88': True, 'feature_89': True, 'feature_90': True, 'feature_91': False, 'feature_92': False, 'feature_93': True, 'feature_94': False, 'feature_95': False, 'feature_96': True, 'feature_97': True, 'feature_98': False, 'feature_99': False, 'feature_100': False, 'feature_101': True, 'feature_102': False, 'feature_103': False, 'feature_104': True, 'feature_105': True, 'feature_106': False, 'feature_107': True, 'feature_108': True, 'feature_109': True, 'feature_110': False, 'feature_111': True, 'feature_112': False, 'feature_113': False, 'feature_114': True, 'feature_115': True, 'feature_116': False, 'feature_117': True, 'feature_118': False, 'feature_119': True, 'feature_120': True, 'feature_121': True, 'feature_122': True, 'feature_123': True, 'feature_124': False, 'feature_125': True, 'feature_126': False, 'feature_127': True, 'feature_128': False, 'feature_129': False, 'feature_130': True, 'feature_131': True, 'feature_132': False, 'feature_133': True, 'feature_134': False, 'feature_135': True, 'feature_136': False, 'feature_137': False, 'feature_138': False, 'feature_139': True, 'feature_140': True, 'feature_141': True, 'feature_142': True, 'feature_143': False, 'feature_144': True, 'feature_145': False, 'feature_146': True, 'feature_147': True, 'feature_148': False, 'feature_149': True, 'feature_150': False, 'feature_151': False, 'feature_152': True, 'feature_153': False, 'feature_154': True, 'feature_155': False, 'feature_156': True, 'feature_157': False, 'feature_158': True, 'feature_159': True, 'feature_160': True, 'feature_161': False, 'feature_162': False, 'feature_163': True, 'feature_164': True, 'feature_165': False, 'feature_166': True, 'feature_167': False, 'feature_168': True, 'feature_169': True, 'feature_170': False, 'feature_171': False, 'feature_172': True, 'feature_173': True, 'feature_174': False, 'feature_175': True, 'feature_176': True, 'feature_177': True, 'feature_178': True, 'feature_179': False, 'feature_180': True, 'feature_181': False, 'feature_182': True, 'feature_183': False, 'feature_184': False, 'feature_185': False, 'feature_186': True, 'feature_187': False, 'feature_188': True, 'feature_189': False, 'feature_190': True, 'feature_191': True, 'feature_192': True, 'feature_193': True, 'feature_194': True, 'feature_195': True, 'feature_196': False, 'feature_197': False, 'feature_198': False, 'feature_199': True, 'feature_200': False, 'feature_201': True, 'feature_202': False, 'feature_203': False, 'feature_204': True, 'classifier': 'NuSVC', 'kernel': 'rbf', 'nu': 0.578203273073227, 'gamma': 0.08923782216001382}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'feature_0': CategoricalDistribution(choices=(True, False)), 'feature_1': CategoricalDistribution(choices=(True, False)), 'feature_2': CategoricalDistribution(choices=(True, False)), 'feature_3': CategoricalDistribution(choices=(True, False)), 'feature_4': CategoricalDistribution(choices=(True, False)), 'feature_5': CategoricalDistribution(choices=(True, False)), 'feature_6': CategoricalDistribution(choices=(True, False)), 'feature_7': CategoricalDistribution(choices=(True, False)), 'feature_8': CategoricalDistribution(choices=(True, False)), 'feature_9': CategoricalDistribution(choices=(True, False)), 'feature_10': CategoricalDistribution(choices=(True, False)), 'feature_11': CategoricalDistribution(choices=(True, False)), 'feature_12': CategoricalDistribution(choices=(True, False)), 'feature_13': CategoricalDistribution(choices=(True, False)), 'feature_14': CategoricalDistribution(choices=(True, False)), 'feature_15': CategoricalDistribution(choices=(True, False)), 'feature_16': CategoricalDistribution(choices=(True, False)), 'feature_17': CategoricalDistribution(choices=(True, False)), 'feature_18': CategoricalDistribution(choices=(True, False)), 'feature_19': CategoricalDistribution(choices=(True, False)), 'feature_20': CategoricalDistribution(choices=(True, False)), 'feature_21': CategoricalDistribution(choices=(True, False)), 'feature_22': CategoricalDistribution(choices=(True, False)), 'feature_23': CategoricalDistribution(choices=(True, False)), 'feature_24': CategoricalDistribution(choices=(True, False)), 'feature_25': CategoricalDistribution(choices=(True, False)), 'feature_26': CategoricalDistribution(choices=(True, False)), 'feature_27': CategoricalDistribution(choices=(True, False)), 'feature_28': CategoricalDistribution(choices=(True, False)), 'feature_29': CategoricalDistribution(choices=(True, False)), 'feature_30': CategoricalDistribution(choices=(True, False)), 'feature_31': CategoricalDistribution(choices=(True, False)), 'feature_32': CategoricalDistribution(choices=(True, False)), 'feature_33': CategoricalDistribution(choices=(True, False)), 'feature_34': CategoricalDistribution(choices=(True, False)), 'feature_35': CategoricalDistribution(choices=(True, False)), 'feature_36': CategoricalDistribution(choices=(True, False)), 'feature_37': CategoricalDistribution(choices=(True, False)), 'feature_38': CategoricalDistribution(choices=(True, False)), 'feature_39': CategoricalDistribution(choices=(True, False)), 'feature_40': CategoricalDistribution(choices=(True, False)), 'feature_41': CategoricalDistribution(choices=(True, False)), 'feature_42': CategoricalDistribution(choices=(True, False)), 'feature_43': CategoricalDistribution(choices=(True, False)), 'feature_44': CategoricalDistribution(choices=(True, False)), 'feature_45': CategoricalDistribution(choices=(True, False)), 'feature_46': CategoricalDistribution(choices=(True, False)), 'feature_47': CategoricalDistribution(choices=(True, False)), 'feature_48': CategoricalDistribution(choices=(True, False)), 'feature_49': CategoricalDistribution(choices=(True, False)), 'feature_50': CategoricalDistribution(choices=(True, False)), 'feature_51': CategoricalDistribution(choices=(True, False)), 'feature_52': CategoricalDistribution(choices=(True, False)), 'feature_53': CategoricalDistribution(choices=(True, False)), 'feature_54': CategoricalDistribution(choices=(True, False)), 'feature_55': CategoricalDistribution(choices=(True, False)), 'feature_56': CategoricalDistribution(choices=(True, False)), 'feature_57': CategoricalDistribution(choices=(True, False)), 'feature_58': CategoricalDistribution(choices=(True, False)), 'feature_59': CategoricalDistribution(choices=(True, False)), 'feature_60': CategoricalDistribution(choices=(True, False)), 'feature_61': CategoricalDistribution(choices=(True, False)), 'feature_62': CategoricalDistribution(choices=(True, False)), 'feature_63': CategoricalDistribution(choices=(True, False)), 'feature_64': CategoricalDistribution(choices=(True, False)), 'feature_65': CategoricalDistribution(choices=(True, False)), 'feature_66': CategoricalDistribution(choices=(True, False)), 'feature_67': CategoricalDistribution(choices=(True, False)), 'feature_68': CategoricalDistribution(choices=(True, False)), 'feature_69': CategoricalDistribution(choices=(True, False)), 'feature_70': CategoricalDistribution(choices=(True, False)), 'feature_71': CategoricalDistribution(choices=(True, False)), 'feature_72': CategoricalDistribution(choices=(True, False)), 'feature_73': CategoricalDistribution(choices=(True, False)), 'feature_74': CategoricalDistribution(choices=(True, False)), 'feature_75': CategoricalDistribution(choices=(True, False)), 'feature_76': CategoricalDistribution(choices=(True, False)), 'feature_77': CategoricalDistribution(choices=(True, False)), 'feature_78': CategoricalDistribution(choices=(True, False)), 'feature_79': CategoricalDistribution(choices=(True, False)), 'feature_80': CategoricalDistribution(choices=(True, False)), 'feature_81': CategoricalDistribution(choices=(True, False)), 'feature_82': CategoricalDistribution(choices=(True, False)), 'feature_83': CategoricalDistribution(choices=(True, False)), 'feature_84': CategoricalDistribution(choices=(True, False)), 'feature_85': CategoricalDistribution(choices=(True, False)), 'feature_86': CategoricalDistribution(choices=(True, False)), 'feature_87': CategoricalDistribution(choices=(True, False)), 'feature_88': CategoricalDistribution(choices=(True, False)), 'feature_89': CategoricalDistribution(choices=(True, False)), 'feature_90': CategoricalDistribution(choices=(True, False)), 'feature_91': CategoricalDistribution(choices=(True, False)), 'feature_92': CategoricalDistribution(choices=(True, False)), 'feature_93': CategoricalDistribution(choices=(True, False)), 'feature_94': CategoricalDistribution(choices=(True, False)), 'feature_95': CategoricalDistribution(choices=(True, False)), 'feature_96': CategoricalDistribution(choices=(True, False)), 'feature_97': CategoricalDistribution(choices=(True, False)), 'feature_98': CategoricalDistribution(choices=(True, False)), 'feature_99': CategoricalDistribution(choices=(True, False)), 'feature_100': CategoricalDistribution(choices=(True, False)), 'feature_101': CategoricalDistribution(choices=(True, False)), 'feature_102': CategoricalDistribution(choices=(True, False)), 'feature_103': CategoricalDistribution(choices=(True, False)), 'feature_104': CategoricalDistribution(choices=(True, False)), 'feature_105': CategoricalDistribution(choices=(True, False)), 'feature_106': CategoricalDistribution(choices=(True, False)), 'feature_107': CategoricalDistribution(choices=(True, False)), 'feature_108': CategoricalDistribution(choices=(True, False)), 'feature_109': CategoricalDistribution(choices=(True, False)), 'feature_110': CategoricalDistribution(choices=(True, False)), 'feature_111': CategoricalDistribution(choices=(True, False)), 'feature_112': CategoricalDistribution(choices=(True, False)), 'feature_113': CategoricalDistribution(choices=(True, False)), 'feature_114': CategoricalDistribution(choices=(True, False)), 'feature_115': CategoricalDistribution(choices=(True, False)), 'feature_116': CategoricalDistribution(choices=(True, False)), 'feature_117': CategoricalDistribution(choices=(True, False)), 'feature_118': CategoricalDistribution(choices=(True, False)), 'feature_119': CategoricalDistribution(choices=(True, False)), 'feature_120': CategoricalDistribution(choices=(True, False)), 'feature_121': CategoricalDistribution(choices=(True, False)), 'feature_122': CategoricalDistribution(choices=(True, False)), 'feature_123': CategoricalDistribution(choices=(True, False)), 'feature_124': CategoricalDistribution(choices=(True, False)), 'feature_125': CategoricalDistribution(choices=(True, False)), 'feature_126': CategoricalDistribution(choices=(True, False)), 'feature_127': CategoricalDistribution(choices=(True, False)), 'feature_128': CategoricalDistribution(choices=(True, False)), 'feature_129': CategoricalDistribution(choices=(True, False)), 'feature_130': CategoricalDistribution(choices=(True, False)), 'feature_131': CategoricalDistribution(choices=(True, False)), 'feature_132': CategoricalDistribution(choices=(True, False)), 'feature_133': CategoricalDistribution(choices=(True, False)), 'feature_134': CategoricalDistribution(choices=(True, False)), 'feature_135': CategoricalDistribution(choices=(True, False)), 'feature_136': CategoricalDistribution(choices=(True, False)), 'feature_137': CategoricalDistribution(choices=(True, False)), 'feature_138': CategoricalDistribution(choices=(True, False)), 'feature_139': CategoricalDistribution(choices=(True, False)), 'feature_140': CategoricalDistribution(choices=(True, False)), 'feature_141': CategoricalDistribution(choices=(True, False)), 'feature_142': CategoricalDistribution(choices=(True, False)), 'feature_143': CategoricalDistribution(choices=(True, False)), 'feature_144': CategoricalDistribution(choices=(True, False)), 'feature_145': CategoricalDistribution(choices=(True, False)), 'feature_146': CategoricalDistribution(choices=(True, False)), 'feature_147': CategoricalDistribution(choices=(True, False)), 'feature_148': CategoricalDistribution(choices=(True, False)), 'feature_149': CategoricalDistribution(choices=(True, False)), 'feature_150': CategoricalDistribution(choices=(True, False)), 'feature_151': CategoricalDistribution(choices=(True, False)), 'feature_152': CategoricalDistribution(choices=(True, False)), 'feature_153': CategoricalDistribution(choices=(True, False)), 'feature_154': CategoricalDistribution(choices=(True, False)), 'feature_155': CategoricalDistribution(choices=(True, False)), 'feature_156': CategoricalDistribution(choices=(True, False)), 'feature_157': CategoricalDistribution(choices=(True, False)), 'feature_158': CategoricalDistribution(choices=(True, False)), 'feature_159': CategoricalDistribution(choices=(True, False)), 'feature_160': CategoricalDistribution(choices=(True, False)), 'feature_161': CategoricalDistribution(choices=(True, False)), 'feature_162': CategoricalDistribution(choices=(True, False)), 'feature_163': CategoricalDistribution(choices=(True, False)), 'feature_164': CategoricalDistribution(choices=(True, False)), 'feature_165': CategoricalDistribution(choices=(True, False)), 'feature_166': CategoricalDistribution(choices=(True, False)), 'feature_167': CategoricalDistribution(choices=(True, False)), 'feature_168': CategoricalDistribution(choices=(True, False)), 'feature_169': CategoricalDistribution(choices=(True, False)), 'feature_170': CategoricalDistribution(choices=(True, False)), 'feature_171': CategoricalDistribution(choices=(True, False)), 'feature_172': CategoricalDistribution(choices=(True, False)), 'feature_173': CategoricalDistribution(choices=(True, False)), 'feature_174': CategoricalDistribution(choices=(True, False)), 'feature_175': CategoricalDistribution(choices=(True, False)), 'feature_176': CategoricalDistribution(choices=(True, False)), 'feature_177': CategoricalDistribution(choices=(True, False)), 'feature_178': CategoricalDistribution(choices=(True, False)), 'feature_179': CategoricalDistribution(choices=(True, False)), 'feature_180': CategoricalDistribution(choices=(True, False)), 'feature_181': CategoricalDistribution(choices=(True, False)), 'feature_182': CategoricalDistribution(choices=(True, False)), 'feature_183': CategoricalDistribution(choices=(True, False)), 'feature_184': CategoricalDistribution(choices=(True, False)), 'feature_185': CategoricalDistribution(choices=(True, False)), 'feature_186': CategoricalDistribution(choices=(True, False)), 'feature_187': CategoricalDistribution(choices=(True, False)), 'feature_188': CategoricalDistribution(choices=(True, False)), 'feature_189': CategoricalDistribution(choices=(True, False)), 'feature_190': CategoricalDistribution(choices=(True, False)), 'feature_191': CategoricalDistribution(choices=(True, False)), 'feature_192': CategoricalDistribution(choices=(True, False)), 'feature_193': CategoricalDistribution(choices=(True, False)), 'feature_194': CategoricalDistribution(choices=(True, False)), 'feature_195': CategoricalDistribution(choices=(True, False)), 'feature_196': CategoricalDistribution(choices=(True, False)), 'feature_197': CategoricalDistribution(choices=(True, False)), 'feature_198': CategoricalDistribution(choices=(True, False)), 'feature_199': CategoricalDistribution(choices=(True, False)), 'feature_200': CategoricalDistribution(choices=(True, False)), 'feature_201': CategoricalDistribution(choices=(True, False)), 'feature_202': CategoricalDistribution(choices=(True, False)), 'feature_203': CategoricalDistribution(choices=(True, False)), 'feature_204': CategoricalDistribution(choices=(True, False)), 'classifier': CategoricalDistribution(choices=('SVC', 'NuSVC')), 'kernel': CategoricalDistribution(choices=('linear', 'poly', 'rbf', 'sigmoid')), 'nu': FloatDistribution(high=0.99, log=False, low=0.01, step=None), 'gamma': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=1022, value=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_col = []\n",
    "for i in range(205):\n",
    "    f_col.append(\"feature_%s\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feature = [best_params[f] for f in f_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for k in best_params.keys():\n",
    "    if not k in f_col:\n",
    "        temp[k] = best_params[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/RBP_eclip/All/merge/ensembl__merge__RBPpred__RBPPWM_10-3_or.npy\n",
    "# data/RBP_eclip/All/merge/ensembl__y.npy\n",
    "x = np.load(\"data/RBP_eclip/All/merge/ensembl__merge__RBPpred__RBPPWM_10-3_or.npy\")\n",
    "y = np.load(\"data/RBP_eclip/All/merge/ensembl__y.npy\")\n",
    "perf_json = svm_function.cv_esvm_perf(data_x=x[:, select_feature], \n",
    "                                      data_y=y,\n",
    "                                      size=10,\n",
    "                                      max_iter=1000,\n",
    "                                      log=False,\n",
    "                                      fold=10,\n",
    "                                      **temp\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s.json' % (\"data/RBP_eclip/output/ensembl__merge_RBP_PWM__fs\"), 'w') as fp:\n",
    "    json.dump(perf_json, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_proba predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_proba_perf(train_proba, train_y, test_proba, test_y, auto_threshold=False):\n",
    "    if auto_threshold:\n",
    "        print(\"Auto_threshold\")\n",
    "    \n",
    "    acc_array = []\n",
    "    recall_array = []\n",
    "    prec_array = []\n",
    "    spec_array = []\n",
    "    npv_array = []\n",
    "    f1sc_array = []\n",
    "    auroc_array = []\n",
    "    for i in range(len(test_y)):\n",
    "        y_train = np.array(train_y[i])\n",
    "        y_train_proba = np.array(train_proba[i])[:, 1]\n",
    "        \n",
    "        y_test = np.array(test_y[i])\n",
    "        y_test_proba = np.array(test_proba[i])[:, 1]\n",
    "        \n",
    "        threshold = 0.5\n",
    "        if auto_threshold:\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_proba)\n",
    "            diff = []\n",
    "            for i in range(len(thresholds)):\n",
    "                pred = np.where(y_train_proba > thresholds[i], 1, 0)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_train, pred).ravel()\n",
    "                \n",
    "                # recall = tp / (fn + tp)\n",
    "                # prec = tp / (fp + tp)\n",
    "                # spec = tn / (tn + fp)\n",
    "                # npv = tn / (tn + fn)\n",
    "                # diff.append(recall * prec)\n",
    "                \n",
    "                # recall = (tp / (fn + tp)) ** 2\n",
    "                # prec = (tp / (fp + tp)) ** 2\n",
    "                # spec = (tn / (tn + fp)) ** 2\n",
    "                # npv =  (tn / (tn + fn)) ** 2\n",
    "                # diff.append(recall + prec + spec + npv)\n",
    "                \n",
    "                diff.append(metrics.roc_auc_score(y_train, pred))\n",
    "\n",
    "            diff = np.array(diff)\n",
    "\n",
    "            diff[np.isnan(diff)] = 0\n",
    "            threshold = thresholds[np.argmax(diff)]\n",
    "            \n",
    "        y_test_pred = np.where(y_test_proba > threshold, 1, 0)\n",
    "        try:\n",
    "            roc_score = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "            auroc_array.append(roc_score)\n",
    "        except:\n",
    "            auroc_array.append(0.5)\n",
    "        \n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "        \n",
    "        acc_array.append((tn + tp) / (tn + fp + fn + tp))\n",
    "        recall_array.append(tp / (fn + tp))\n",
    "        prec_array.append(tp / (fp + tp))\n",
    "        spec_array.append(tn / (tn + fp))\n",
    "        npv_array.append(tn / (tn + fn))\n",
    "        f1sc_array.append(2 * (tp / (fn + tp)) * (tp / (fp + tp)) / ((tp / (fn + tp)) + (tp / (fp + tp))))\n",
    "    \n",
    "    json_dict = {\n",
    "        \"fold Accy\": acc_array,\n",
    "        \"avg Accy\": sum(acc_array) / len(acc_array),\n",
    "        \"std Accy\": np.std(acc_array),\n",
    "        \"fold Recall\": recall_array,\n",
    "        \"avg Recall\": sum(recall_array) / len(recall_array),\n",
    "        \"std Recall\": np.std(recall_array),\n",
    "        \"fold Prec\": prec_array,\n",
    "        \"avg Prec\": sum(prec_array) / len(prec_array),\n",
    "        \"std Prec\": np.std(prec_array),\n",
    "        \"fold Spec\": spec_array,\n",
    "        \"avg Spec\": sum(spec_array) / len(spec_array),\n",
    "        \"std Spec\": np.std(spec_array),\n",
    "        \"fold Npv\": npv_array,\n",
    "        \"avg Npv\": sum(npv_array) / len(npv_array),\n",
    "        \"std Npv\": np.std(npv_array),\n",
    "        \"fold F1sc\": f1sc_array,\n",
    "        \"avg F1sc\": sum(f1sc_array) / len(f1sc_array),\n",
    "        \"std F1sc\": np.std(f1sc_array),\n",
    "        \"fold AUROC\": auroc_array,\n",
    "        \"avg AUROC\": sum(auroc_array) / len(auroc_array),\n",
    "        \"std AUROC\": np.std(auroc_array),\n",
    "    }\n",
    "    \n",
    "    return json_dict\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"data/Pse_in_One2/my_DB/output/predict_output/\"\n",
    "output_file = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensembl_has_rbpelic__EIF3D__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n",
      "ensembl_has_rbpelic__XRCC6__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n",
      "ensembl_has_rbpelic__DDX3X__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n",
      "ensembl_has_rbpelic__SRSF9__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n",
      "ensembl_has_rbpelic__TAF15__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n",
      "ensembl_has_rbpelic__HNRNPC__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n",
      "ensembl_has_rbpelic__AQR__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n",
      "ensembl_has_rbpelic__ZNF622__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n",
      "ensembl_has_rbpelic__FUS__train_y__svm_p4_e512_f10.json\n",
      "Auto_threshold\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"data/Pse_in_One2/my_DB/output/predict/\"\n",
    "onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "rbp_list = []\n",
    "for file_name in onlyfiles:\n",
    "    if (\"__train_y__svm_p4_e512_f10.json\" in file_name) and not \".dvc\" in file_name and not file_name in output_file:\n",
    "        print(file_name)\n",
    "        f = open(dir_path + file_name)\n",
    "        pred_proba = json.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        f = open(pred_proba[\"hp\"])\n",
    "        hp = json.load(f)\n",
    "        f.close()\n",
    "        # if hp[\"avg Recall\"] == 1:\n",
    "        ppp = pred_proba_perf(pred_proba[\"train_proba\"], \n",
    "                            pred_proba[\"train_y\"], \n",
    "                            pred_proba[\"test_proba\"], \n",
    "                            pred_proba[\"test_y\"], \n",
    "                            auto_threshold=True)\n",
    "        \n",
    "        ppp[\"input\"] = pred_proba[\"input\"]\n",
    "        ppp[\"label\"] = pred_proba[\"label\"]\n",
    "        ppp[\"hp\"] = pred_proba[\"hp\"]\n",
    "        \n",
    "        with open('data/Pse_in_One2/my_DB/output/predict_output/%s' % (file_name), 'w') as fp:\n",
    "            json.dump(ppp, fp)\n",
    "        # for key, val in ppp.items():\n",
    "        #     if \"avg\" in key:\n",
    "        #         print(key, val, hp[key])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`for x in *.json.json; do  mv $x ${x%.*.*}.json; done;`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall, prec, spec, npv ** 2\n",
    "NSUN2\n",
    "avg Accy 0.9690926777019493 0.9689496685656438\n",
    "avg Recall 0.39391304347826084 0.5556107660455487\n",
    "avg Prec 0.9611648941922775 0.7568310802548311\n",
    "avg Spec 0.9991699251543869 0.9905675744898831\n",
    "avg Npv 0.9692587113568318 0.9770818341530194\n",
    "avg F1sc 0.5578832101838608 0.6393702828424033\n",
    "avg AUROC 0.696541484316324 0.8810535817970357\n",
    "\n",
    "NIPBL\n",
    "avg Accy 0.8211532270920431 0.2179993109229005\n",
    "avg Recall 0.599671052631579 1.0\n",
    "avg Prec 0.5893865216348267 0.2179993109229005\n",
    "avg Spec 0.882893650299784 0.0\n",
    "avg Npv 0.8879207871503813 nan\n",
    "avg F1sc 0.5935713000824612 0.357962939469001\n",
    "avg AUROC 0.7412823514656814 0.792660783091631\n",
    "### auroc\n",
    "NSUN2\n",
    "avg Accy 0.9694512549120098 0.9689496685656438\n",
    "avg Recall 0.4127536231884058 0.5556107660455487\n",
    "avg Prec 0.944960647656037 0.7568310802548311\n",
    "avg Spec 0.9985663223199295 0.9905675744898831\n",
    "avg Npv 0.9701775512149207 0.9770818341530194\n",
    "avg F1sc 0.5696783483784433 0.6393702828424033\n",
    "avg AUROC 0.7056599727541677 0.8810535817970357\n",
    "\n",
    "NIPBL\n",
    "avg Accy 0.8423090253672936 0.2179993109229005\n",
    "avg Recall 0.525 1.0\n",
    "avg Prec 0.6790399997573106 0.2179993109229005\n",
    "avg Spec 0.9307659835686476 0.0\n",
    "avg Npv 0.8755203267619791 nan\n",
    "avg F1sc 0.5916631645749215 0.357962939469001\n",
    "avg AUROC 0.7278829917843238 0.792660783091631"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load(\"data/merge_data/seq_rbp/pse_in_one2__rbp_10-3_-log10__train__y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hpo_svm_train', 'x', 'esvm_e512_p10_f10_s10_t1000_hasNu.json']\n",
      "x\n",
      "['hpo_svm_train', 'x', 'esvm_e512_p10_f10_s10_t10000_hasNu.json']\n",
      "x\n",
      "['hpo_svm_train', 'x', 'esvm_e1024_p10_f10_s10_t1000_hasNu.json']\n",
      "x\n",
      "['hpo_svm_train', 'x', 'esvm_e1024_p10_f10_s10_t10000_hasNu.json']\n",
      "x\n",
      "['hpo_svm_train', 'pseinone_rbpeclip_x', 'esvm_e512_p10_f10_s10_t1000_hasNu.json']\n",
      "pseinone_rbpeclip_x\n",
      "['hpo_svm_train', 'pseinone_rbpeclip_x', 'esvm_e512_p10_f10_s10_t10000_hasNu.json']\n",
      "pseinone_rbpeclip_x\n",
      "['hpo_svm_train', 'pseinone_rbpeclip_x', 'esvm_e1024_p10_f10_s10_t1000_hasNu.json']\n",
      "pseinone_rbpeclip_x\n",
      "['hpo_svm_train', 'pseinone_rbpeclip_x', 'esvm_e1024_p10_f10_s10_t10000_hasNu.json']\n",
      "pseinone_rbpeclip_x\n",
      "['hpo_svm_train', 'pseinone_rbpeclip_x', 'esvm_e512_p10_f10_s20_t10000_hasNu.json']\n",
      "pseinone_rbpeclip_x\n",
      "['hpo_svm_train', 'pseinone_rbpeclip_x', 'esvm_e512_p10_f10_s20_t1000_hasNu.json']\n",
      "pseinone_rbpeclip_x\n",
      "['hpo_svm_train', 'pseinone_rbpeclip_x', 'esvm_e1024_p10_f10_s20_t10000_hasNu.json']\n",
      "pseinone_rbpeclip_x\n",
      "['hpo_svm_train', 'pseinone_rbpeclip_x', 'esvm_e1024_p10_f10_s20_t1000_hasNu.json']\n",
      "pseinone_rbpeclip_x\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"data/RBP_eclip/output/\"\n",
    "onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "for file_name in onlyfiles:\n",
    "    if (\"hpo_svm_train__\" in file_name) and (\"_hasNu.json\" in file_name) and not \".dvc\" in file_name:\n",
    "        file_name_list = file_name.split(\"__\")\n",
    "        print(file_name_list)\n",
    "        file_str = file_name_list[1]\n",
    "        file_hp = file_name_list[-1][:-len(\".json\")]\n",
    "        \n",
    "        print(file_str)\n",
    "        f = open(dir_path + file_name)\n",
    "        perf = json.load(f)\n",
    "        f.close()\n",
    "        num = np.load(\"data/RBP_eclip/train/\" + file_str + \".npy\").shape[1]\n",
    "        perf_list.append([file_str, num, file_hp,\n",
    "                          perf['avg Accy'], perf['std Accy'],\n",
    "                          perf['avg Recall'], perf['std Recall'],\n",
    "                          perf['avg Prec'], perf['std Prec'],\n",
    "                          perf['avg Spec'], perf['std Spec'],\n",
    "                          perf['avg Npv'], perf['std Npv'],\n",
    "                          perf['avg F1sc'], perf['std F1sc'],\n",
    "                          perf['avg AUROC'], perf['std AUROC']\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-4', 'esvm_e512_p10_f10_s10_t1000_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-4\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-5', 'esvm_e512_p10_f10_s10_t1000_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-5\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-5', 'esvm_e512_p10_f10_s10_t10000_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-5\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-5', 'esvm_e1024_p10_f10_s10_t1000_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-5\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-4', 'esvm_e512_p10_f10_s10_t10000_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-4\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-4', 'esvm_e1024_p10_f10_s10_t1000_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-4\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-5', 'esvm_e1024_p10_f10_s10_t10000_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-5\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-4', 'esvm_e1024_p10_f10_s10_t10000_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-4\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-5', 'esvm_e512_p10_f10_s10_t10000_nor_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-5\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-4', 'esvm_e512_p10_f10_s10_t10000_nor_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-4\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-4', 'esvm_e512_p10_f10_s10_t1000_nor_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-4\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-5', 'esvm_e512_p10_f10_s10_t1000_nor_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-5\n",
      "['hpo_svm_train', 'rbp_10-3_-log10', 'esvm_e512_p10_f10_s10_t10000_nor_hasNu.json']\n",
      "rbp_10-3_-log10\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-5', 'esvm_e1024_p10_f10_s10_t1000_nor_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-5\n",
      "['hpo_svm_train', 'rbp_10-3_-log10', 'esvm_e512_p10_f10_s10_t1000_nor_hasNu.json']\n",
      "rbp_10-3_-log10\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-4', 'esvm_e1024_p10_f10_s10_t1000_nor_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-4\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-5', 'esvm_e1024_p10_f10_s10_t10000_nor_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-5\n",
      "['hpo_svm_train', 'rbp_10-3_-log10_utest1e-4', 'esvm_e1024_p10_f10_s10_t10000_nor_hasNu.json']\n",
      "rbp_10-3_-log10_utest1e-4\n",
      "['hpo_svm_train', 'rbp_10-3_-log10', 'esvm_e1024_p10_f10_s10_t1000_nor_hasNu.json']\n",
      "rbp_10-3_-log10\n",
      "['hpo_svm_train', 'rbp_10-3_-log10', 'esvm_e1024_p10_f10_s10_t10000_nor_hasNu.json']\n",
      "rbp_10-3_-log10\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"data/merge_data/seq_rbp_output/\"\n",
    "onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "for file_name in onlyfiles:\n",
    "    if (\"hpo_svm_train__\" in file_name) and (\"_hasNu.json\" in file_name) and not \"pse\" in file_name and not \".dvc\" in file_name:\n",
    "        file_name_list = file_name.split(\"__\")\n",
    "        print(file_name_list)\n",
    "        # file_str = file_name_list[1] + \"__\" + file_name_list[2]\n",
    "        file_str = file_name_list[1]\n",
    "        file_hp = file_name_list[-1][:-len(\".json\")]\n",
    "        \n",
    "        print(file_str)\n",
    "        f = open(dir_path + file_name)\n",
    "        perf = json.load(f)\n",
    "        f.close()\n",
    "        # num = np.load(\"data/merge_data/seq_rbp/transcript2pse_in_one__train__x.npy\").shape[1]\n",
    "        num = np.load(\"data/merge_data/seq_rbp/\" + file_str + \"__train__x.npy\").shape[1]\n",
    "        perf_list.append([file_str, num, file_hp,\n",
    "                          perf['avg Accy'], perf['std Accy'],\n",
    "                          perf['avg Recall'], perf['std Recall'],\n",
    "                          perf['avg Prec'], perf['std Prec'],\n",
    "                          perf['avg Spec'], perf['std Spec'],\n",
    "                          perf['avg Npv'], perf['std Npv'],\n",
    "                          perf['avg F1sc'], perf['std F1sc'],\n",
    "                          perf['avg AUROC'], perf['std AUROC']\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_binary__10-4__filter\n",
      "train_binary__10-3__filter\n",
      "train_-log10__10-3__filter\n",
      "train_-log10__10-4__filter\n"
     ]
    }
   ],
   "source": [
    "# dir_path = \"data/merge_data/output/\"\n",
    "dir_path = \"data/RBP-PWM/output/\"\n",
    "onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "\n",
    "for file_name in onlyfiles:\n",
    "    if (\"__esvm_p10_f10_s10__v230221.json\" in file_name) and not \".dvc\" in file_name:\n",
    "        file_str = file_name[:-len(\"__esvm_p10_f10_s10__v230221.json\")]\n",
    "    # if (\"__esvm_p10_f10_s10__v230118_v2.json\" in file_name) and not \".dvc\" in file_name:\n",
    "    #     file_str = file_name[:-len(\"__esvm_p10_f10_s10__v230118_v2.json\")]\n",
    "        \n",
    "        if \"train__\" in file_str:\n",
    "            file_str = file_str.replace(\"train\", \"train_binary\")\n",
    "        print(file_str)\n",
    "        f = open(dir_path + file_name)\n",
    "        perf = json.load(f)\n",
    "        f.close()\n",
    "        num = np.load(\"data/RBP-PWM/train/\" + file_str + \"__x.npy\").shape[1]\n",
    "        perf_list.append([file_str, num,\n",
    "                          perf['avg Accy'], perf['std Accy'],\n",
    "                          perf['avg Recall'], perf['std Recall'],\n",
    "                          perf['avg Prec'], perf['std Prec'],\n",
    "                          perf['avg Spec'], perf['std Spec'],\n",
    "                          perf['avg Npv'], perf['std Npv'],\n",
    "                          perf['avg F1sc'], perf['std F1sc'],\n",
    "                          perf['avg AUROC'], perf['std AUROC'],\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(perf_list, columns=[\"esvm_s10\", \"nums\", \"hp\", \n",
    "                                 \"avg Accy\", \"std Accy\",\n",
    "                                 \"avg Recall\", \"std Recall\",\n",
    "                                 \"avg Prec\", \"std Prec\",\n",
    "                                 \"avg Spec\", \"std Spec\",\n",
    "                                 \"avg Npv\", \"std Npv\",\n",
    "                                 \"avg F1sc\", \"std F1sc\",\n",
    "                                 \"avg AUROC\", \"std AUROC\"\n",
    "                                 ]).sort_values(\"esvm_s10\").to_csv(\"data/RBP_eclip/output/v230426__pref.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2264, 1008)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"data/linear_features/point/benchmark/train/k234p10nor2n3_train.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file_str',\n",
       " 0.7062645551932929,\n",
       " 0.02728313642700328,\n",
       " 0.724779861183052,\n",
       " 0.027373539164752204,\n",
       " 0.9191811524505985,\n",
       " 0.013461697940586836,\n",
       " 0.585483870967742,\n",
       " 0.0729476979210487,\n",
       " 0.8102467384324458,\n",
       " 0.019711847903634495,\n",
       " 0.6936555352450462,\n",
       " 0.04558923440965074]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"data/merge_data/output/Kmer_k3__DACC_lag2__SC-PseDNC-General_all_index_svmf10p4e512.json\")\n",
    "perf = json.load(f)\n",
    "f.close()\n",
    "[\"file_str\", \n",
    "        perf['avg Accy'], perf['std Accy'],\n",
    "        perf['avg Recall'], perf['std Recall'],\n",
    "        perf['avg Prec'], perf['std Prec'],\n",
    "        perf['avg Spec'], perf['std Spec'],\n",
    "        perf['avg F1sc'], perf['std F1sc'],\n",
    "        perf['avg AUROC'], perf['std AUROC'],\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import average\n",
    "\n",
    "\n",
    "dir_path = \"data/linear_features/point/benchmark/output/\"\n",
    "onlyfiles = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "perf_list = []\n",
    "\n",
    "for file_name in onlyfiles:\n",
    "    if \"_svmf10p4e512.json\" in file_name and not \".dvc\" in file_name and not \"train\" in file_name:\n",
    "        \n",
    "        file_str = file_name[:-5]\n",
    "        f = open(dir_path + file_name)\n",
    "        perf = json.load(f)\n",
    "        f.close()\n",
    "        perf_list.append([file_str, np.load(\"data/linear_features/point/benchmark/train/\" + file_name[:-18] + \"_train.npy\").shape[1],\n",
    "                          perf['avg Accy'], perf['std Accy'],\n",
    "                          perf['avg Recall'], perf['std Recall'],\n",
    "                          perf['avg Prec'], perf['std Prec'],\n",
    "                          perf['avg Spec'], perf['std Spec'],\n",
    "                          perf['avg F1sc'], perf['std F1sc'],\n",
    "                          perf['avg AUROC'], perf['std AUROC'],\n",
    "                          ])\n",
    "        # npv_array = []\n",
    "        # for i in range(len(perf['confusion matrix'])):\n",
    "        #     tn, fp, fn, tp = np.array(perf['confusion matrix'][i][1]).flatten()\n",
    "        #     acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "        #     recall = tp / (fn + tp)\n",
    "        #     prec = (tp / (fp + tp))\n",
    "        #     spec = (tn / (tn + fp))\n",
    "        #     npv = (tn / (tn + fn))\n",
    "        #     f1sc = (2 * (tp / (fn + tp)) * (tp / (fp + tp)) / ((tp / (fn + tp)) + (tp / (fp + tp))))\n",
    "        #     npv_array.append(npv)\n",
    "        # print(npv_array)\n",
    "        # print(sum(npv_array)/ len(npv_array), np.std(npv_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(perf_list, columns=['file name', \"num\", 'avg Accy', 'std Accy', 'avg Recall', 'std Recall', 'avg Prec', 'std Prec', 'avg Spec', 'std Spec', 'avg F1sc', 'std F1sc', 'avg AUROC', 'std AUROC']).sort_values('file name').to_csv(dir_path + \"svmf10p4e512_pref_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jand_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "681206c3b8dadcd0ad9db9cda94afb40592645b096d359128b6de26b00c40796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
